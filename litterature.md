# Litererature
This is a working document for literature. This is much for sharing and organizing material as opposed to the Zotero which is for citation management.

## Model suggestions
- [DeBERTa v3](https://arxiv.org/abs/2111.09543?context=cs)

## Training
- Performance [docs](https://huggingface.co/docs/transformers/performance) for transformers
- [Deepspeed blog post](https://www.deepspeed.ai/news/2021/12/09/deepspeed-moe-nlg.html)

potentially also:
- [xformer](https://devblog.pytorchlightning.ai/part-i-simplifying-transformer-research-with-xformers-lightning-a715737b8ad4)


# Collaborative models
- Blog Post by Collin on building models like [open-source code](https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html).


# Large scale models:
- Google recently released 3 new papers on large scale language models, there is a blog post detailing it [here](https://deepmind.com/blog/article/language-modelling-at-scale).

# Data cleaning
- [Deduplicating Training Data Makes Language Models Better](https://arxiv.org/abs/2107.06499)
